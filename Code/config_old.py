config = {
    # 'Device':
    "processor": "M",  # 'Other' or 'M' - M is for Mac M1/M2/M3 processors
   
    # 'File Locations':
    "file": "fly_train.h5ad",  # name of the data file
    "eval_file": "fly_eval.h5ad",  # name of the data file for final evaluation
    "original_file": "fly_original.h5ad",  # name of the original data file
    "batch_file": "fly_train_batch.h5ad",  # name of the batch corrected data file
    "batch_eval_file": "fly_eval_batch.h5ad",  # name of the batch corrected data file for final evaluation
    "batch_original_file": "fly_original_batch.h5ad",  # name of the original data file
   
    # 'Data Parameters':
    "tissue": "head",  # 'head' or 'body'
    "model_type": "CNN",  # 'CNN' or 'MLP' or 'XGBoost' or 'random_forest' or logistic_regression'
    "encoding_variable": "age",  # variable to use for encoding - (sex_age), (sex), or (age)
    "batch_correction": False,  # True to perform batch correction, False to skip, (ONLY FOR AGE ENCODING)
    "sex_type": "all",  # 'all', male, female, male/female, female/male'
    "tissue_type": "all",  # head/body, body/head', all
    "samples": 200000,  # total number of samples (cells) for training (total = 289981)
    "variables": 15992,  # total number of variables (genes) for training (total = 15992)
    "split_by": "random",
    "train_sex": "all",  # '
    "test_sex": "all",  # '
    "train_tissue": "all",  # '
    "test_tissue": "all",  # '
    
    # 'Cell types':
    "cell_type": "all",  # all, CMS neuron, epithelial cell, fat cell, glial cell, muscle cell, sensory neuron' [ CASE SENSITIVE ]
    
    # 'Data Processing':
    "normalize": "no",  # normalize data - either yes or no
    "load_model": "no",  # 'yes' to load a saved model, 'no' to skip
    "preprocess_required": "yes",  # 'yes' to preprocess data, 'no' to load preprocessed data
    "save_data": "yes",  # 'yes' to save preprocessed data, 'no' to skip
    "run_EDA": "no",  # run EDA - either yes or no
    "include_mix": "no",  # inlcude mix sex - either yes or no

    # 'Gene balancing':
    "balance_genes": "no",  # 'yes' to balance genes, 'no' to skip, if using you must also set one option in 'LNC genes' or 'Data Preprocessing' to 'yes'
    "balance_lnc_genes": "no",  # 'yes' to keep only autosomal genes, 'no' to skip, if using you must also set one option in 'LNC genes' to 'yes'
    
    # 'Data Preprocessing':
    "remove_sex_genes": "no",  # 'yes' to remove non-autosomal genes, 'no' to skip
    "remove_autosomal_genes": "no",  # 'yes' to remove autosomal genes, 'no' to skip
    
    # 'LNC genes':
    "only_keep_lnc_genes": "no",  # 'yes' to keep genes beginning with lnc, 'no' to skip (Yes Overrides all other gene removals)
    "remove_lnc_genes": "no",  # 'yes' to remove genes beginning with lnc, 'no' to skip
    
    # 'Other gene selects':
    "remove_unaccounted_genes": False,  # True to remove unaccounted genes, False to skip
    "select_batch_genes": "no",  # 'yes' to select batch genes, 'no' to skip
    "shuffle_genes": "no",  # 'yes' to shuffle genes, 'no' to skip
    "highly_variable_genes": "no",  # 'yes' to select highly variable genes, 'no' to skip
   
    # 'Feature Importance and Visualizations':
    "run_visualization": "yes", # 'yes' to ..
    "run_interpreter": False, # 'yes' to ..
    "SHAP": "no",  # 'yes' to compute SHAP values, 'no' to skip
    "save_SHAP": "no",  # 'yes' to save SHAP visuals, 'no' to skip
    "reference_size": 5000,  # Reference data for computing SHAP values - how many samples
    "SHAP_test": 5000,  # Test data for computing SHAP values - how many samples
    "LIME": "no",  # 'yes' to compute LIME explanations, 'no' to skip
    "LIME_perturbations": 1000,  # Number of perturbed samples generated by LIME for each instance interpretation.
   
    # 'Split':
    "validation_split": 0.2,  # fraction of data to use for validation
    "test_split": 0.2,  # fraction of data to use for testing
    "random_state": 42,  # random state for reproducibility - default = 42. Others used: 11, 23, 777, 999
   
    # 'Training':
    "epochs": 15,  # number of epochs for model trainingv
    "batch_size": 250,  # size of data batches for model training
    "early_stopping_patience": 5,  # patience for early stopping
    "custom_loss": "categorical_crossentropy",
    "metrics": ["accuracy", "AUC"],
    
    # 'MLP Model':
    "mlp_units": [128, 256, 128],
    "mlp_dropout_rate": 0.3,
    "mlp_learning_rate": 0.0006,
    "mlp_custom_activation": "relu",
    "mlp_reference_size": 1000,  # Reference data for computing SHAP values - how many samples
    
    # 'CNN Model':
    "cnn_filters": [32, 64, 128],  # Example filters
    "cnn_kernel_sizes": [3, 3, 3],  # Example kernel sizes
    "cnn_strides": [1, 1, 1],  # Example strides
    "cnn_paddings": ["same", "same", "same"],  # Example paddings
    "cnn_pool_sizes": [2, 2, 2],  # Example pooling sizes
    "cnn_pool_strides": [2, 2, 2],  # Example pooling strides
    "cnn_units": [128, 64],  # Dense layer units
    "cnn_dropout_rate": 0.5,  # Dropout rate
    "cnn_learning_rate": 0.001,  # Learning rate
    "cnn_custom_activation": "relu",  # Activation for dense layers
    
    # 'XGBoost Model':
    "xgb_learning_rate": 0.1,  # learning rate
    "xgb_max_depth": 6,  # maximum depth of tree
    "xgb_min_child_weight": 1,  # minimum sum of instance weight needed in a child
    "xgb_subsample": 1,  # subsample ratio of the training instance
    "xgb_colsample_bytree": 1,  # subsample ratio of columns when constructing each tree
    "xgb_early_stopping_rounds": 10,  # early stopping rounds
    "xgb_seed": 42,  # random seed
    "xgb_tree_method": "gpu_hist",  # 'auto', 'exact', 'approx', 'hist', 'gpu_hist'
    "xgb_predictor": "gpu_predictor",  # 'auto', 'cpu_predictor', 'gpu_predictor'
    "xgb_n_estimators": 100,  # number of trees
    "xgb_random_state": 42,  # random state
    
    # 'Random Forest Model':
    "rf_n_estimators": 100,  # number of trees
    "rf_criterion": "gini",  # 'gini' or 'entropy'
    "rf_max_depth": None,  # maximum depth of tree
    "rf_min_samples_split": 2,  # minimum number of samples required to split an internal node
    "rf_min_samples_leaf": 1,  # minimum number of samples required to be at a leaf node
    "rf_max_features": "sqrt",  # 'auto', 'sqrt', 'log2'
    "rf_bootstrap": True,  # method of selecting samples for training each tree
    "rf_oob_score": True,  # whether to use out-of-bag samples to estimate the generalization accuracy
    "rf_n_jobs": -1,  # number of jobs to run in parallel
    "rf_random_state": 42,  # random state
    
    # 'Logistic Regression Model':
    "lr_penalty": "l1",  # 'l1' or 'l2' or 'elasticnet'
    "lr_solver": "liblinear",  # 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'
    "lr_l1_ratio": 0.5,  # only used if penalty is 'elasticnet'
    "lr_max_iter": 100,  # maximum number of iterations
    "lr_random_state": 42,  # random state

    # 'Batch Correction':

    # 'Setup':
    "strata": "age",  # Column used for stratification
    "tissue": "head",  # Tissue type (e.g., 'head', 'body')
    "seed": 42,        # Random seed for reproducibility
    "batch": False,    # Whether to use batch-corrected data
    "split_size": 5000,  # Number of samples per class to split
    "strata_columns": ["age"],  # Columns used for stratification during verification
}
